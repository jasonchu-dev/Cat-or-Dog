{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3276d4e0-2aee-4496-9195-16a27a29cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 11:08:15.680534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-30 11:08:15.785687: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-30 11:08:15.788928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-30 11:08:15.788945: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-30 11:08:16.359104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-30 11:08:16.359212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-30 11:08:16.359220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fad701d-6f1b-4b74-8a8d-202d195b3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 200\n",
    "data = []\n",
    "\n",
    "for _id, category in enumerate(os.listdir('PetImages')):\n",
    "    path = os.path.join('PetImages', category)\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_arr = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE)\n",
    "            img_arr = cv.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
    "            data.append([img_arr, _id])\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc3ad9b-5bd1-4264-aa41-804ed918c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c984ead-b0f8-41d9-9d02-12964fc8359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for img_arr, _id in data[:500]:\n",
    "    X.append(img_arr)\n",
    "    y.append(_id)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "X = X/255\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd00ca7-6094-437e-b254-459f67fbfaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 11:08:31.470589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-30 11:08:31.470736: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-30 11:08:31.470802: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2f2deb97f862): /proc/driver/nvidia/version does not exist\n",
      "2022-12-30 11:08:31.472240: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "23/23 [==============================] - 5s 190ms/step - loss: 1.1868 - accuracy: 0.4911 - val_loss: 0.6949 - val_accuracy: 0.4600\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 4s 182ms/step - loss: 0.6710 - accuracy: 0.5600 - val_loss: 0.7116 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 4s 180ms/step - loss: 0.6027 - accuracy: 0.6822 - val_loss: 0.6912 - val_accuracy: 0.7200\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 4s 184ms/step - loss: 0.5080 - accuracy: 0.7422 - val_loss: 0.8532 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 4s 188ms/step - loss: 0.4258 - accuracy: 0.7933 - val_loss: 0.9061 - val_accuracy: 0.5800\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 4s 181ms/step - loss: 0.2940 - accuracy: 0.8644 - val_loss: 0.9427 - val_accuracy: 0.5800\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 4s 188ms/step - loss: 0.1806 - accuracy: 0.9356 - val_loss: 1.2788 - val_accuracy: 0.5400\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 4s 181ms/step - loss: 0.1406 - accuracy: 0.9378 - val_loss: 1.6042 - val_accuracy: 0.5600\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 4s 179ms/step - loss: 0.1964 - accuracy: 0.9444 - val_loss: 1.5144 - val_accuracy: 0.5400\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 4s 183ms/step - loss: 0.0863 - accuracy: 0.9689 - val_loss: 1.8803 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 4s 187ms/step - loss: 0.0398 - accuracy: 0.9889 - val_loss: 2.0232 - val_accuracy: 0.5800\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 4s 182ms/step - loss: 0.0428 - accuracy: 0.9889 - val_loss: 2.0746 - val_accuracy: 0.5800\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 4s 184ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 2.5844 - val_accuracy: 0.5600\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 4s 181ms/step - loss: 0.0244 - accuracy: 0.9978 - val_loss: 2.8068 - val_accuracy: 0.6600\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 4s 181ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 2.7664 - val_accuracy: 0.6400\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 4s 181ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 3.0363 - val_accuracy: 0.6400\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 4s 180ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.9426 - val_accuracy: 0.6600\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 4s 181ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.1548 - val_accuracy: 0.6400\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 4s 182ms/step - loss: 8.6539e-04 - accuracy: 1.0000 - val_loss: 3.2309 - val_accuracy: 0.6400\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 4s 184ms/step - loss: 7.0496e-04 - accuracy: 1.0000 - val_loss: 3.2936 - val_accuracy: 0.6400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f015c7bdea0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=20, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b73d7d8-a541-40b6-9ba2-fa02fc53453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 198, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 67712)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8667264   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,760,065\n",
      "Trainable params: 8,760,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae748ce-a602-436b-9857-75eb96935380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa80ca7-0bbf-4c99-ad81-7794018d8b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 198, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 67712)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8667264   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,760,065\n",
      "Trainable params: 8,760,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "savedModel=tf.keras.models.load_model('model.h5')\n",
    "savedModel.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
